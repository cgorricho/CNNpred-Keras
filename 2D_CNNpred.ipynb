{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "XcSpDjZCg8QD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5040,
     "status": "ok",
     "timestamp": 1673476232958,
     "user": {
      "displayName": "Carlos Gorricho",
      "userId": "06137727384740707636"
     },
     "user_tz": 300
    },
    "id": "XcSpDjZCg8QD",
    "outputId": "34e96f84-8155-40ef-9cf7-184d03c61ac0"
   },
   "outputs": [],
   "source": [
    "# corre !pip install pathlib2 si est√° en Google Colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    !pip install pathlib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea46a49",
   "metadata": {
    "executionInfo": {
     "elapsed": 7712,
     "status": "ok",
     "timestamp": 1673476240665,
     "user": {
      "displayName": "Carlos Gorricho",
      "userId": "06137727384740707636"
     },
     "user_tz": 300
    },
    "id": "5ea46a49"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from os.path import join\n",
    "from sklearn.metrics import accuracy_score as accuracy, f1_score, mean_absolute_error as mae\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from pathlib2 import Path\n",
    "from tensorflow.keras import backend as K, callbacks\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dabcee9",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1673476240666,
     "user": {
      "displayName": "Carlos Gorricho",
      "userId": "06137727384740707636"
     },
     "user_tz": 300
    },
    "id": "7dabcee9"
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision_pos = precision(y_true, y_pred)\n",
    "    recall_pos = recall(y_true, y_pred)\n",
    "    precision_neg = precision((K.ones_like(y_true) - y_true), (K.ones_like(y_pred) - K.clip(y_pred, 0, 1)))\n",
    "    recall_neg = recall((K.ones_like(y_true) - y_true), (K.ones_like(y_pred) - K.clip(y_pred, 0, 1)))\n",
    "    f_posit = 2 * ((precision_pos * recall_pos) / (precision_pos + recall_pos + K.epsilon()))\n",
    "    f_neg = 2 * ((precision_neg * recall_neg) / (precision_neg + recall_neg + K.epsilon()))\n",
    "\n",
    "    return (f_posit + f_neg) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d762bf",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1673476240667,
     "user": {
      "displayName": "Carlos Gorricho",
      "userId": "06137727384740707636"
     },
     "user_tz": 300
    },
    "id": "57d762bf"
   },
   "outputs": [],
   "source": [
    "def load_data(file_fir):\n",
    "    try:\n",
    "        df_raw = pd.read_csv(file_fir, index_col='Date') # parse_dates=['Date'])\n",
    "    except IOError:\n",
    "        print(\"IO ERROR\")\n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9b5ec2",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1673476240667,
     "user": {
      "displayName": "Carlos Gorricho",
      "userId": "06137727384740707636"
     },
     "user_tz": 300
    },
    "id": "ef9b5ec2"
   },
   "outputs": [],
   "source": [
    "def costruct_data_warehouse(ROOT_PATH, file_names):\n",
    "    global number_of_stocks\n",
    "    global samples_in_each_stock\n",
    "    global number_feature\n",
    "    global order_stocks\n",
    "    data_warehouse = {}\n",
    "\n",
    "    for stock_file_name in file_names:\n",
    "\n",
    "        file_dir = os.path.join(ROOT_PATH, stock_file_name)\n",
    "        ## Loading Data\n",
    "        try:\n",
    "            df_raw = load_data(file_dir)\n",
    "        except ValueError:\n",
    "            print(\"Couldn't Read {} file\".format(file_dir))\n",
    "\n",
    "        number_of_stocks += 1\n",
    "\n",
    "        data = df_raw\n",
    "        df_name = data['Name'][0]\n",
    "        order_stocks.append(df_name)\n",
    "        del data['Name']\n",
    "\n",
    "        target = (data['Close'][predict_day:] / data['Close'][:-predict_day].values).astype(int)\n",
    "        data = data[:-predict_day]\n",
    "        target.index = data.index\n",
    "        # Becasue of using 200 days Moving Average as one of the features\n",
    "        data = data[200:]\n",
    "        data = data.fillna(0)\n",
    "        data['target'] = target\n",
    "        target = data['target']\n",
    "        # data['Date'] = data['Date'].apply(lambda x: x.weekday())\n",
    "        del data['target']\n",
    "\n",
    "        number_feature = data.shape[1]\n",
    "        samples_in_each_stock = data.shape[0]\n",
    "\n",
    "        train_data = data[data.index < '2016-04-21']\n",
    "        train_data1 = scale(train_data)\n",
    "        # print train_data.shape\n",
    "        train_target1 = target[target.index < '2016-04-21']\n",
    "        train_data = train_data1[:int(0.75 * train_data1.shape[0])]\n",
    "        train_target = train_target1[:int(0.75 * train_target1.shape[0])]\n",
    "\n",
    "        valid_data = scale(train_data1[int(0.75 * train_data1.shape[0]) - seq_len:])\n",
    "        valid_target = train_target1[int(0.75 * train_target1.shape[0]) - seq_len:]\n",
    "\n",
    "        data = pd.DataFrame(scale(data.values), columns=data.columns)\n",
    "        data.index = target.index\n",
    "        test_data = data[data.index >= '2016-04-21']\n",
    "        test_target = target[target.index >= '2016-04-21']\n",
    "\n",
    "        data_warehouse[df_name] = [train_data, train_target, np.array(test_data), np.array(test_target), valid_data,\n",
    "                                   valid_target]\n",
    "\n",
    "    return data_warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d67ad5",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1673476240667,
     "user": {
      "displayName": "Carlos Gorricho",
      "userId": "06137727384740707636"
     },
     "user_tz": 300
    },
    "id": "08d67ad5"
   },
   "outputs": [],
   "source": [
    "def cnn_data_sequence_separately(tottal_data, tottal_target, data, target, seque_len):\n",
    "    for index in range(data.shape[0] - seque_len + 1):\n",
    "        tottal_data.append(data[index: index + seque_len])\n",
    "        tottal_target.append(target[index + seque_len - 1])\n",
    "\n",
    "    return tottal_data, tottal_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f488b59",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1673476240910,
     "user": {
      "displayName": "Carlos Gorricho",
      "userId": "06137727384740707636"
     },
     "user_tz": 300
    },
    "id": "2f488b59"
   },
   "outputs": [],
   "source": [
    "def cnn_data_sequence(data_warehouse, seq_len):\n",
    "    tottal_train_data = []\n",
    "    tottal_train_target = []\n",
    "    tottal_valid_data = []\n",
    "    tottal_valid_target = []\n",
    "    tottal_test_data = []\n",
    "    tottal_test_target = []\n",
    "\n",
    "    for key, value in data_warehouse.items():\n",
    "        tottal_train_data, tottal_train_target = cnn_data_sequence_separately(tottal_train_data, tottal_train_target,\n",
    "                                                                              value[0], value[1], seq_len)\n",
    "        tottal_test_data, tottal_test_target = cnn_data_sequence_separately(tottal_test_data, tottal_test_target,\n",
    "                                                                            value[2], value[3], seq_len)\n",
    "        tottal_valid_data, tottal_valid_target = cnn_data_sequence_separately(tottal_valid_data, tottal_valid_target,\n",
    "                                                                              value[4], value[5], seq_len)\n",
    "\n",
    "    tottal_train_data = np.array(tottal_train_data)\n",
    "    tottal_train_target = np.array(tottal_train_target)\n",
    "    tottal_test_data = np.array(tottal_test_data)\n",
    "    tottal_test_target = np.array(tottal_test_target)\n",
    "    tottal_valid_data = np.array(tottal_valid_data)\n",
    "    tottal_valid_target = np.array(tottal_valid_target)\n",
    "\n",
    "    tottal_train_data = tottal_train_data.reshape(tottal_train_data.shape[0], tottal_train_data.shape[1],\n",
    "                                                  tottal_train_data.shape[2], 1)\n",
    "    tottal_test_data = tottal_test_data.reshape(tottal_test_data.shape[0], tottal_test_data.shape[1],\n",
    "                                                tottal_test_data.shape[2], 1)\n",
    "    tottal_valid_data = tottal_valid_data.reshape(tottal_valid_data.shape[0], tottal_valid_data.shape[1],\n",
    "                                                  tottal_valid_data.shape[2], 1)\n",
    "\n",
    "    return tottal_train_data, tottal_train_target, tottal_test_data, tottal_test_target, tottal_valid_data, tottal_valid_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "530a93e0",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1673476240910,
     "user": {
      "displayName": "Carlos Gorricho",
      "userId": "06137727384740707636"
     },
     "user_tz": 300
    },
    "id": "530a93e0"
   },
   "outputs": [],
   "source": [
    "def sklearn_acc(model, test_data, test_target):\n",
    "    overall_results = model.predict(test_data)\n",
    "    test_pred = (overall_results > 0.5).astype(int)\n",
    "    acc_results = [mae(overall_results, test_target), accuracy(test_pred, test_target),\n",
    "                   f1_score(test_pred, test_target, average='macro')]\n",
    "\n",
    "    return acc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "572efc2f",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1673476240910,
     "user": {
      "displayName": "Carlos Gorricho",
      "userId": "06137727384740707636"
     },
     "user_tz": 300
    },
    "id": "572efc2f"
   },
   "outputs": [],
   "source": [
    "def train(data_warehouse, i):\n",
    "    seq_len = 60\n",
    "    epochs = 200\n",
    "    drop = 0.1\n",
    "\n",
    "    global cnn_train_data, cnn_train_target, cnn_test_data, cnn_test_target, cnn_valid_data, cnn_valid_target\n",
    "\n",
    "    if i == 1:\n",
    "        print('sequencing ...')\n",
    "        cnn_train_data, cnn_train_target, cnn_test_data, cnn_test_target, cnn_valid_data, cnn_valid_target = cnn_data_sequence(\n",
    "            data_warehouse, seq_len)\n",
    "\n",
    "    my_file = Path(join(Base_dir,\n",
    "        '2D-models/best-{}-{}-{}-{}-{}.h5'.format(epochs, seq_len, number_filter, drop, i)))\n",
    "    filepath = join(Base_dir, '2D-models/best-{}-{}-{}-{}-{}.h5'.format(epochs, seq_len, number_filter, drop, i))\n",
    "    if my_file.is_file():\n",
    "        print('loading model')\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(' fitting model to target')\n",
    "        model = Sequential()\n",
    "        #\n",
    "        # layer 1\n",
    "        model.add(\n",
    "            Conv2D(number_filter[0], (1, number_feature), activation='relu', input_shape=(seq_len, number_feature, 1)))\n",
    "        # layer 2\n",
    "        model.add(Conv2D(number_filter[1], (3, 1), activation='relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2, 1)))\n",
    "\n",
    "        # layer 3\n",
    "        model.add(Conv2D(number_filter[2], (3, 1), activation='relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2, 1)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dropout(drop))\n",
    "\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        print(model.summary())\n",
    "\n",
    "        model.compile(optimizer='Adam', loss='mae', metrics=['acc', f1])\n",
    "\n",
    "        best_model = callbacks.ModelCheckpoint(filepath, monitor='val_f1', verbose=0, save_best_only=True,\n",
    "                                               save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "        model.fit(cnn_train_data, cnn_train_target, epochs=epochs, batch_size=128, verbose=1,\n",
    "                        validation_data=(cnn_valid_data, cnn_valid_target), callbacks=[best_model])\n",
    "    model = load_model(filepath, custom_objects={'f1': f1})\n",
    "\n",
    "    return model, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da40da43",
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1673476241125,
     "user": {
      "displayName": "Carlos Gorricho",
      "userId": "06137727384740707636"
     },
     "user_tz": 300
    },
    "id": "da40da43"
   },
   "outputs": [],
   "source": [
    "def cnn_data_sequence_pre_train(data, target, seque_len):\n",
    "    new_data = []\n",
    "    new_target = []\n",
    "    for index in range(data.shape[0] - seque_len + 1):\n",
    "        new_data.append(data[index: index + seque_len])\n",
    "        new_target.append(target[index + seque_len - 1])\n",
    "\n",
    "    new_data = np.array(new_data)\n",
    "    new_target = np.array(new_target)\n",
    "\n",
    "    new_data = new_data.reshape(new_data.shape[0], new_data.shape[1], new_data.shape[2], 1)\n",
    "\n",
    "    return new_data, new_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71425e68",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1673476241126,
     "user": {
      "displayName": "Carlos Gorricho",
      "userId": "06137727384740707636"
     },
     "user_tz": 300
    },
    "id": "71425e68"
   },
   "outputs": [],
   "source": [
    "def prediction(data_warehouse, model, seque_len, order_stocks, cnn_results):\n",
    "    for name in order_stocks:\n",
    "        value = data_warehouse[name]\n",
    "        # train_data, train_target = cnn_data_sequence_pre_train(value[0], value[1], seque_len)\n",
    "        test_data, test_target = cnn_data_sequence_pre_train(value[2], value[3], seque_len)\n",
    "        # valid_data, valid_target = cnn_data_sequence_pre_train(value[4], value[5], seque_len)\n",
    "\n",
    "        cnn_results.append(sklearn_acc(model, test_data, test_target)[2])\n",
    "\n",
    "    return cnn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec532d31",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673476241126,
     "user": {
      "displayName": "Carlos Gorricho",
      "userId": "06137727384740707636"
     },
     "user_tz": 300
    },
    "id": "ec532d31"
   },
   "outputs": [],
   "source": [
    "def run_cnn_ann(data_warehouse, order_stocks):\n",
    "    cnn_results = []\n",
    "    # dnn_results = []\n",
    "    iterate_no = 4\n",
    "    for i in range(1, iterate_no):\n",
    "        K.clear_session()\n",
    "        print(i)\n",
    "        model, seq_len = train(data_warehouse, i)\n",
    "        # cnn_results, dnn_results = prediction(data_warehouse, model, seq_len, order_stocks, cnn_results)\n",
    "        cnn_results = prediction(data_warehouse, model, seq_len, order_stocks, cnn_results)\n",
    "\n",
    "    cnn_results = np.array(cnn_results)\n",
    "    cnn_results = cnn_results.reshape(iterate_no - 1, len(order_stocks))\n",
    "    cnn_results = pd.DataFrame(cnn_results, columns=order_stocks)\n",
    "    cnn_results = cnn_results.append([cnn_results.mean(), cnn_results.max(), cnn_results.std()], ignore_index=True)\n",
    "    cnn_results.to_csv(join(Base_dir, '2D-models/new results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dt-KlxnhLg8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dt-KlxnhLg8",
    "outputId": "6f6353df-ae1e-462e-e67b-fbb2488848d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab\n"
     ]
    }
   ],
   "source": [
    "# the function str(get_ipython()) returns a string that either contains 'google.colab' or not\n",
    "# Reference: https://stackoverflow.com/questions/53581278/test-if-notebook-is-running-on-google-colab\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    from google.colab import drive      # when the notebook runs on Jupyter this import will produce and error if placed in the import cell above, \n",
    "                                        # it can only be used after it has been established that the notebook is on Google CoLab\n",
    "    print('Google Drive', drive.mount('/content/drive'))\n",
    "    Base_dir = '/content/drive/MyDrive/AIML/Proyectos/Time_Series/CNNpred-Keras'\n",
    "\n",
    "else:\n",
    "    print('Not running on CoLab')\n",
    "    Base_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "514b9320",
   "metadata": {
    "id": "514b9320"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Processed_DJI.csv',\n",
       " 'Processed_NASDAQ.csv',\n",
       " 'Processed_NYSE.csv',\n",
       " 'Processed_RUSSELL.csv',\n",
       " 'Processed_SP.csv',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base_dir = '/content/drive/MyDrive/AIML/Proyectos/CNNpred-Keras/'\n",
    "TRAIN_ROOT_PATH = join(Base_dir, 'Dataset')\n",
    "train_file_names = os.listdir(join(Base_dir, 'Dataset'))\n",
    "train_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8034beb6",
   "metadata": {
    "id": "8034beb6"
   },
   "outputs": [],
   "source": [
    "# if moving average = 0 then we have no moving average\n",
    "seq_len = 60\n",
    "moving_average_day = 0\n",
    "number_of_stocks = 0\n",
    "number_feature = 0\n",
    "samples_in_each_stock = 0\n",
    "number_filter = [8, 8, 8]\n",
    "predict_day = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c80d628",
   "metadata": {
    "id": "7c80d628"
   },
   "outputs": [],
   "source": [
    "# initialize each variable as an empty list\n",
    "cnn_train_data, cnn_train_target, cnn_test_data, cnn_test_target, cnn_valid_data, cnn_valid_target = ([] for i in\n",
    "                                                                                                      range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "209ce1bd",
   "metadata": {
    "id": "209ce1bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data ...\n",
      "IO ERROR\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'df_raw' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp\\ipykernel_16320\\3337095918.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loading train data ...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0morder_stocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata_warehouse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcostruct_data_warehouse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_ROOT_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_file_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# order_stocks = data_warehouse.keys()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Temp\\ipykernel_16320\\303049492.py\u001b[0m in \u001b[0;36mcostruct_data_warehouse\u001b[1;34m(ROOT_PATH, file_names)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m## Loading Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mdf_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Couldn't Read {} file\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Temp\\ipykernel_16320\\261535143.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(file_fir)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"IO ERROR\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'df_raw' referenced before assignment"
     ]
    }
   ],
   "source": [
    "print('Loading train data ...')\n",
    "order_stocks = []\n",
    "data_warehouse = costruct_data_warehouse(TRAIN_ROOT_PATH, train_file_names)\n",
    "# order_stocks = data_warehouse.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b080d86b",
   "metadata": {
    "id": "b080d86b"
   },
   "outputs": [],
   "source": [
    "print('number of stocks = '), number_of_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f1614",
   "metadata": {
    "id": "ae3f1614"
   },
   "outputs": [],
   "source": [
    "run_cnn_ann(data_warehouse, order_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc3f520",
   "metadata": {
    "id": "4bc3f520"
   },
   "outputs": [],
   "source": [
    "print(cnn_train_data.shape)\n",
    "print(cnn_train_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1964ca9f",
   "metadata": {
    "id": "1964ca9f",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1df76e8e7890335dc20f17a43050e0beb567cd8375c96e084c20e3208a4bfe80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
